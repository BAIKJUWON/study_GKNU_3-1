## 1장: 데이터마이닝 기본

**데이터마이닝 의미**  
- 대규모 데이터로부터 의미 있는 패턴이나 지식을 추출하는 과정.
- 통계학, 머신러닝, 데이터베이스 기술이 결합된 영역.

**주요 구성요소**  
- 데이터 클리닝(결측치, 이상치 제거)
- 데이터 통합
- 데이터 선택
- 데이터 변환
- 데이터마이닝(패턴 추출)
- 패턴 평가
- 지식 표현

**데이터마이닝 프로세스**  
1. 목적 파악
2. 데이터 수집 및 전처리
3. 데이터 탐색 및 정제
4. 데이터 축소 및 분할
5. 분석유형 결정(분류, 예측, 군집)
6. 기법 선택
7. 알고리즘 적용
8. 결과 해석
9. 모형 활용

**용어 위주 정리**  
- 분류(Classification): 집단 나누기
- 예측(Prediction): 연속값 예측
- 연관규칙(Association Rules): 항목 간 관계 찾기
- 차원축소(Dimensionality Reduction): 변수 수 줄이기
- 데이터 탐색(Data Exploration): 데이터 이해, 시각화

---

## 2장: 데이터로부터 지식 얻기

**기초통계량**  
- 분포: 데이터가 퍼져 있는 모양
- 평균: 중심값
- 비대칭(왜도, Skewness): 한쪽으로 치우침
- 분산: 퍼져 있는 정도

**데이터 종류**  
- 연속형: 키, 몸무게(수치)
- 범주형: 성별, 지역(구분)
- 척도:
  - 명목척도: 단순 구분(남/여)
  - 서열척도: 순서 O, 간격 X(직급)
  - 구간척도: 간격 O, 절대 0 X(온도)
  - 비율척도: 간격 O, 절대 0 O(무게)

**히스토그램 정의**  
- 데이터를 구간별로 나누고 빈도를 시각화한 그래프.

**산포도(Scatter plot)**  
- 두 변수 간 관계를 점으로 표시.

**피벗테이블**  
- 데이터를 요약, 집계하는 테이블. 숫자형(합계), 범주형(도수, 백분율) 모두 사용.

---

## 3장: 데이터 전처리와 과적합

**어떻게 할 것인가? (전처리)**
- 결측치 처리(Missing Value): 제거 또는 대체
- 이상치(극단치) 처리: 제거 또는 변환
- 데이터 변환: 정규화(표준화) 필요 시 수행

**과적합(Overfitting)**
- 학습 데이터에는 잘 맞지만 새로운 데이터에는 성능 저하.
- 원인: 변수가 많을 때, 모델 복잡할 때.
- 해결: 변수 줄이기, 데이터 분할(학습/검증/평가), 정규화

---

## 4장: 불필요한 컬럼 제거와 차원축소

**불필요한 컬럼 제거**
- 일련번호, 의미 없는 식별자 삭제.

**범주형 변수 범주 줄이기**
- 범주가 많은 경우, 비슷한 범주 합치기.

**차원축소 방법**
- 상관관계 분석: 강한 상관이 있는 변수 제거
- 주성분 분석(PCA): 여러 변수를 선형 결합하여 소수의 변수로 축소

**주성분분석(PCA)**
- 고차원 데이터를 선형결합으로 축소.
- 데이터 간 중복정보 제거, 해석 용이성 증가.
- 분석 전 정규화 필요.

---

## 5장: 성능측정과 해석

**기본 개념**
- 정오분류표(Confusion Matrix) 사용
- 정확도(Accuracy) = (TP + TN) / 전체
- 민감도(Sensitivity, Recall): 진짜 긍정 맞춘 비율
- 특이도(Specificity): 진짜 부정 맞춘 비율
- 정밀도(Precision): 예측 긍정 중 진짜 긍정 비율
- F1 Score = 정밀도와 재현율의 조화평균

**행렬 계산**
- 정오분류표를 기준으로 민감도, 특이도, 정밀도, F1 Score 계산

**리프트 차트, ROC Curve**
- 모델 성능 시각화.
- ROC Curve: 민감도 vs 1-특이도 곡선

**비대칭 오분류 비용 고려**
- 예를 들면, 금융에서 파산 예측은 잘못 예측 시 비용이 다름.

---

# 요약 끝



이 파일을 기반으로 추가 요청사항 있으면 알려줘!

